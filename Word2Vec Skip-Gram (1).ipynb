{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (46.0.0.post20200309)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./opt/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eg: Vectorizing a sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`I want a glass of orange juice to go along with my cereal`\n",
    "\n",
    "Tokenizing the sentence -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I want a glass of orange juice to go along with my cereal\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a vocabulary to save mappings from tokens to integer indices. (since programs deal better with integers than words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'i': 1, 'want': 2, 'a': 3, 'glass': 4, 'of': 5, 'orange': 6, 'juice': 7, 'to': 8, 'go': 9, 'along': 10, 'with': 11, 'my': 12, 'cereal': 13}\n"
     ]
    }
   ],
   "source": [
    "# Initialising starting index as 1\n",
    "vocab, index = {}, 1\n",
    "# add a padding token (Start of Sentence) \n",
    "vocab['<pad>'] = 0 \n",
    "for token in tokens:\n",
    "    if token not in vocab: \n",
    "        # Mapping the words to their indices in the sentence\n",
    "        vocab[token] = index \n",
    "        index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an inverse vocabulary to save mappings from integer indices to tokens. (We can use this later when we want to view the word relations visually, once the embeddings are trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'i', 2: 'want', 3: 'a', 4: 'glass', 5: 'of', 6: 'orange', 7: 'juice', 8: 'to', 9: 'go', 10: 'along', 11: 'with', 12: 'my', 13: 'cereal'}\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing the sentence -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "example_sequence = [vocab[token] for token in tokens]\n",
    "print(example_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating skip-grams from one sentence -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "# Setting the window size to be 2\n",
    "window_size = 2\n",
    "\n",
    "# negative samples are set to zero as of now. Negative sampling will be performed further.\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(example_sequence, vocabulary_size = vocab_size, \n",
    "                                                                   window_size = window_size, negative_samples = 0)\n",
    "# total positive skipgram pairs generated for the sentence taken\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing few of the 46 generated positive skip-grams of the given sentence -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5): (a, of)\n",
      "(8, 9): (to, go)\n",
      "(12, 11): (my, with)\n",
      "(13, 11): (cereal, with)\n",
      "(5, 6): (of, orange)\n"
     ]
    }
   ],
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "    # formatted string\n",
    "    print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the positive skipgrams by sliding over given window span using the skipgrams function. To produce, additional skipgram pairs which act as negative examples for training, we sample random word pairs from the vocabulary. We find the number of negative samples in a window for a given target word. Function is called on one skip-gram's target word and context word is passed as true class to exclude it from being sampled. Number of negative samples per positive context word (num_ns), between [5, 20] works best for smaller datasets, while num_ns between [2, 5] is enough for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "of\n",
      "tf.Tensor([[5]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([0 1 3 6], shape=(4,), dtype=int64)\n",
      "['<pad>', 'i', 'a', 'orange']\n"
     ]
    }
   ],
   "source": [
    "# Get target and context words for one positive skip-gram.\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Printing the target and context words\n",
    "print(inverse_vocab[target_word])\n",
    "print(inverse_vocab[context_word])\n",
    "\n",
    "# Set the number of negative samples per positive context. \n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype = \"int64\"), (1, 1))\n",
    "negative_skip_grams, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes = context_class, # class that should be sampled as 'positive'\n",
    "    num_true = 1, # each positive skip-gram has 1 positive context class\n",
    "    num_sampled = num_ns, # number of negative context words to sample\n",
    "    unique = True, # all the negative samples should be unique\n",
    "    range_max = vocab_size, # pick index of the samples from [0, vocab_size]\n",
    "    seed = SEED, # seed for reproducibility (getting same sets later on)\n",
    "    name = \"negative_sampling\" # name of this operation\n",
    ")\n",
    "print(context_class)\n",
    "print(negative_skip_grams)\n",
    "# index is a tensor and is not hashable\n",
    "print([inverse_vocab[index.numpy()] for index in negative_skip_grams])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above method used for negative sampling is giving positive skip-gram pair also. That is true class is also being predicted as negative example while sampling but true class should not be sampled. Fix this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing one training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given positive skip-gram, we now have num_ns negative sampled context words that do not appear in the window size neighborhood of target_word. Batch the 1 positive context_word and num_ns negative context words into one tensor. This produces a set of positive skip-grams (labelled as 1) and negative samples (labelled as 0) for each target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4, 1)\n",
      "()\n",
      "(5,)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "# Add a dimension so you can use concatenation (on the next step).\n",
    "print(negative_skip_grams.shape)\n",
    "negative_skip_grams = tf.expand_dims(negative_skip_grams, 1)\n",
    "print(negative_skip_grams.shape)\n",
    "\n",
    "# Concat positive context word with negative sampled words.\n",
    "context = tf.concat([context_class, negative_skip_grams], 0)\n",
    "\n",
    "# Label first context word as 1 (positive) followed by num_ns 0s (negative).\n",
    "label = tf.constant([1] + [0]*num_ns, dtype = \"int64\") \n",
    "\n",
    "# Reshape target to shape (1,) and context and label to (num_ns+1,).\n",
    "target = tf.squeeze(target_word)\n",
    "context = tf.squeeze(context)\n",
    "label =  tf.squeeze(label)\n",
    "print(target.shape)\n",
    "print(context.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking using an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 3\n",
      "target_word     : a\n",
      "context_indices : [5 0 1 3 6]\n",
      "context_words   : ['of', '<pad>', 'i', 'a', 'orange']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "# context word + num_ns words obtained from negative sampling\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "# label = 1 for context_word and 0 for rest num_ns words\n",
    "print(f\"label           : {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target - shape (1,)\n",
    "context, label - shape - (num_ns + 1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  : tf.Tensor(3, shape=(), dtype=int32)\n",
      "context : tf.Tensor([5 0 1 3 6], shape=(5,), dtype=int64)\n",
      "label   : tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"target  :\", target)\n",
    "print(f\"context :\", context )\n",
    "print(f\"label   :\", label )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training examples obtained from sampling commonly occuring words (such as `the, is, on`) don't add much useful information for the model to learn from.<br>\n",
    "So, subsampling of frequent words as a helpful practice to improve embedding quality.<br>\n",
    "`tf.keras.preprocessing.sequence.skipgrams` function accepts a sampling table argument to encode probabilities of sampling any token.<br><br>\n",
    "`tf.keras.preprocessing.sequence.make_sampling_table` - used to generate a word-frequency rank based probabilistic sampling table and pass it to skipgrams function.<br>\n",
    "Sampling probabilities for a vocab_size of 10 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sampling_table[i]` = probability of sampling the i-th most common word in a dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function assumes a [Zipf's distribution](https://en.wikipedia.org/wiki/Zipf%27s_law) of the word frequencies for sampling. The `tf.random.log_uniform_candidate_sampler` already assumes that the vocabulary frequency follows a log-uniform (Zipf's) distribution. Using these distribution weighted sampling also helps approximate the Noise Contrastive Estimation (NCE) loss with simpler loss functions for training a negative sampling objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling table is built before sampling skip-gram word pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling all the steps described above into a function that can be called on a list of vectorized sentences obtained from any text dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "    # Elements of each training example are appended to these lists.\n",
    "    targets, contexts, labels = [], [], []\n",
    "\n",
    "    # Build the sampling table for vocab_size tokens.\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "    # Iterate over all sequences (sentences) in dataset.\n",
    "    for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "                                              sequence, \n",
    "                                              vocabulary_size = vocab_size,\n",
    "                                              sampling_table = sampling_table,\n",
    "                                              window_size = window_size,\n",
    "                                              negative_samples = 0)\n",
    "\n",
    "        # Iterate over each positive skip-gram pair to produce training examples \n",
    "        # with positive context word and negative samples.\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype = \"int64\"), 1)\n",
    "            negative_skip_grams, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                                              true_classes = context_class,\n",
    "                                              num_true = 1, \n",
    "                                              num_sampled = num_ns, \n",
    "                                              unique = True, \n",
    "                                              range_max = vocab_size, \n",
    "                                              seed = SEED, \n",
    "                                              name = \"negative_sampling\")\n",
    "\n",
    "            # Build context and label vectors (for one target word)\n",
    "            negative_skip_grams = tf.expand_dims(negative_skip_grams, 1)\n",
    "            context = tf.concat([context_class, negative_skip_grams], 0)\n",
    "            label = tf.constant([1] + [0]*num_ns, dtype = \"int64\")\n",
    "\n",
    "            # Append each element from the training example to global lists.\n",
    "            targets.append(target_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "\n",
    "    return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now we dealt with single sentence for skip-gram negative sampling based Word2vec. We now generate training examples from larger list of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading text corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n"
     ]
    }
   ],
   "source": [
    "# Reading text from the file. Let's look at first few lines -\n",
    "\n",
    "with open(path_to_file) as f: \n",
    "    lines = f.read().splitlines()\n",
    "for line in lines[:20]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing object for further use from the non-empty lines\n",
    "# strings of length 0 are discarded \n",
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing the sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuation and converting all text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    return tf.strings.regex_replace(lowercase,'[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size and number of words in a sequence.\n",
    "vocab_size = 4096\n",
    "sequence_length = 10\n",
    "\n",
    "# Text vectorization layer - used to normalize, split, and map strings to integers. \n",
    "vectorize_layer = TextVectorization(\n",
    "                    # calling above method to format the text (remove punc, convert to lowercase)\n",
    "                    standardize = custom_standardization, \n",
    "                    max_tokens = vocab_size,\n",
    "                    output_mode = 'int',\n",
    "                    # Setting output_sequence_length length to pad all samples to same length.\n",
    "                    output_sequence_length = sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating vocabulary from the object we created (which contains non-empty text lines only), by using the `adapt` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds.batch(1024))\n",
    "\n",
    "# Adapting the state of the layer to represent the text corpus\n",
    "# Now we can access the vocabulary using get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"
     ]
    }
   ],
   "source": [
    "# Saving the created vocabulary.\n",
    "\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the vectorize_layer to generate vectors for each element in text_ds (has all non-empty lines of text corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return tf.squeeze(vectorize_layer(text))\n",
    "\n",
    "# Vectorizing the data in text_ds\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting sequences from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have dataset `text_vector_ds` of integer encoded sentences. To produce positive and negative examples, we will have to iterate over each sentence in the dataset and for this, we flatten the datset into list of sentence vector sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the previous `generate_training_data` function we defined takes non-tensorflow inputs (python / numpy functions). So, we use suitable function to enable the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32777\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how sequences looks like by printing few examples -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
      "[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n",
      "[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n",
      "[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences[:5]:\n",
    "    print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating training examples from the sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sequences` - a list of int encoded sentences. We call the `generate_training_data()` function defined earlier to generate training examples for the Word2Vec model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`generate_training_data()` - the function iterates over each word from each sequence to collect positive and negative context words. Length of target, contexts and labels should be same, and each is equal to the total number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32777/32777 [00:05<00:00, 6225.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65127 65127 65127\n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "                                    sequences = sequences, \n",
    "                                    window_size = 2, \n",
    "                                    num_ns = 4, \n",
    "                                    vocab_size = vocab_size, \n",
    "                                    seed = SEED)\n",
    "print(len(targets), len(contexts), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the dataset for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For efficient batching specially when no. of training eg are large, we use `tf.data.Dataset`. We now have object of the same in the form `(target_word, context_word), (label)` elements to train our word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# Adding cache() and prefetch() to improve model performance\n",
    "\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement Word2Vec model as a classifier to distinguish between true context words from positive skip-grams and false context words obtained through negative sampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a dot product between the embeddings of target and context words to obtain predictions for labels and compute loss against true labels in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers used in Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `target_embedding`: To look up the embedding of a word when it appears as a target word. The number of parameters in this layer are equal to `(vocab_size * embedding_dim)`.\n",
    "* `context_embedding`: To look up the embedding of a word when it appears as a context word. The number of parameters in this layer are also `(vocab_size * embedding_dim)`.\n",
    "* `dots`: To compute the dot product of target and context embeddings from a training pair.\n",
    "* `flatten`: To flatten the results of `dots` layer into logits.\n",
    "\n",
    "The first two layers above can be shared as well and we can also use concatenation of both as final Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        # target embedding\n",
    "        self.target_embedding = Embedding(vocab_size, \n",
    "                                          embedding_dim,\n",
    "                                          input_length = 1,\n",
    "                                          name = \"w2v_embedding\", )\n",
    "        # context embedding\n",
    "        self.context_embedding = Embedding(vocab_size, \n",
    "                                           embedding_dim, \n",
    "                                           input_length = num_ns + 1)\n",
    "        self.dots = Dot(axes = (3,2))\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "    # function that accepts (target, context) pairs which can then\n",
    "    # be passed into their corresponding embedding layer.\n",
    "    # Reshape the context_embedding to perform a dot product with \n",
    "    # the target_embedding and return the flattened result.\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        we = self.target_embedding(target)\n",
    "        ce = self.context_embedding(context)\n",
    "        dots = self.dots([ce, we])\n",
    "        return self.flatten(dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining loss function and compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function used - categorical cross entropy<br>\n",
    "Adam's optimizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer = 'adam',\n",
    "                 loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to log training statistics for tensorboard\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with the previously prepared dataset for certain number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/63 [..............................] - ETA: 2s - loss: 1.6095 - accuracy: 0.1992WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0126s vs `on_train_batch_end` time: 0.0576s). Check your callbacks.\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.6081 - accuracy: 0.2357\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5884 - accuracy: 0.5529\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5403 - accuracy: 0.5883\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4580 - accuracy: 0.5638\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3604 - accuracy: 0.5757\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2635 - accuracy: 0.6049\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1728 - accuracy: 0.6400\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0889 - accuracy: 0.6749\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0111 - accuracy: 0.7095\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9391 - accuracy: 0.7396\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8723 - accuracy: 0.7641\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8106 - accuracy: 0.7862\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7537 - accuracy: 0.8062\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7014 - accuracy: 0.8228\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6535 - accuracy: 0.8382\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.8511\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5698 - accuracy: 0.8632\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.8740\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5003 - accuracy: 0.8840\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.8930\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.9014\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.9085\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.9151\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.9208\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.3549 - accuracy: 0.9253\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.3374 - accuracy: 0.9297\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3213 - accuracy: 0.9336\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3066 - accuracy: 0.9369\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.2930 - accuracy: 0.9401\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2805 - accuracy: 0.9430\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2690 - accuracy: 0.9452\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2583 - accuracy: 0.9473\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.9490\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2393 - accuracy: 0.9507\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2308 - accuracy: 0.9522\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2229 - accuracy: 0.9533\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2156 - accuracy: 0.9548\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2087 - accuracy: 0.9560\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2023 - accuracy: 0.9569\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1963 - accuracy: 0.9580\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1908 - accuracy: 0.9588\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1855 - accuracy: 0.9595\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1806 - accuracy: 0.9601\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1760 - accuracy: 0.9607\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1717 - accuracy: 0.9612\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.9616\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.9621\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1602 - accuracy: 0.9625\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1567 - accuracy: 0.9625\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1535 - accuracy: 0.9627\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1505 - accuracy: 0.9631\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 0.9635\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1449 - accuracy: 0.9635\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1423 - accuracy: 0.9637\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1399 - accuracy: 0.9638\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1375 - accuracy: 0.9640\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9640\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9643\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.9644\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9645\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1276 - accuracy: 0.9646\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1258 - accuracy: 0.9646\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9648\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1226 - accuracy: 0.9649\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1211 - accuracy: 0.9651\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9650\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.9649\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.9650\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.9652\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.9652\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1135 - accuracy: 0.9652\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1124 - accuracy: 0.9652\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.9653\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9653\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1094 - accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1085 - accuracy: 0.9654\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.9655\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.9654\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9654\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.9654\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9653\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9654\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.9653\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9654\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1016 - accuracy: 0.9653\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9654\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9654\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0982 - accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0977 - accuracy: 0.9653\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0972 - accuracy: 0.9653\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9654\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9654\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9653\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0950 - accuracy: 0.9654\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0946 - accuracy: 0.9654\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x64229f350>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs = 100, callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking and Analysing the Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the weights from the model using `get_layer()` and `get_weights()`. `get_vocabulary()` function gives the vocabulary to build metadata file with one token per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and saving the vectors and metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "    # skipping 0 since it's padding.\n",
    "    if  index == 0: \n",
    "        continue \n",
    "    vec = weights[index] \n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the `vectors.tsv` and `metadata.tsv` to analyze the obtained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('vectors.tsv')\n",
    "    files.download('metadata.tsv')\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
